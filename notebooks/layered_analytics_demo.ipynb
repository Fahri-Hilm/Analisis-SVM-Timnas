{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fc3a353",
   "metadata": {},
   "source": [
    "# üéØ Layered Analytics Demo\n",
    "\n",
    "**Multi-Layer Opinion Analytics untuk Komentar Timnas Indonesia**\n",
    "\n",
    "Notebook ini mendemonstrasikan:\n",
    "1. Cara melatih model untuk setiap layer (emotion, aspect, toxicity, stance, intent)\n",
    "2. Cara melakukan prediksi berlapis\n",
    "3. Cara mengevaluasi dan menyimpan model\n",
    "4. Cara membuat output comprehensive dengan semua layer\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6988f0ba",
   "metadata": {},
   "source": [
    "## üìö Setup dan Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e6ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Import custom modules\n",
    "from layered_classifier import (\n",
    "    EmotionClassifier, AspectClassifier, \n",
    "    ToxicityClassifier, StanceClassifier, IntentClassifier\n",
    ")\n",
    "from utils.layered_utils import (\n",
    "    create_layered_output_dataframe,\n",
    "    save_metrics_json,\n",
    "    create_comprehensive_report,\n",
    "    multilabel_to_string,\n",
    "    string_to_multilabel,\n",
    "    create_layer_summary\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da76d5d5",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d5804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Extract layered analytics config\n",
    "layer_config = config['layered_analytics']\n",
    "\n",
    "print(\"üéØ Layered Analytics Configuration:\")\n",
    "print(f\"- Enable Emotion: {layer_config['enable_emotion']}\")\n",
    "print(f\"- Enable Aspect: {layer_config['enable_aspect']}\")\n",
    "print(f\"- Enable Toxicity: {layer_config['enable_toxicity']}\")\n",
    "print(f\"- Enable Stance: {layer_config['enable_stance']}\")\n",
    "print(f\"- Enable Intent: {layer_config['enable_intent']}\")\n",
    "print(f\"\\n- Low Confidence Threshold: {layer_config['low_confidence_threshold']}\")\n",
    "print(f\"- Toxicity Threshold: {layer_config['toxicity_threshold']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72421435",
   "metadata": {},
   "source": [
    "## üìä Load and Prepare Labeled Data\n",
    "\n",
    "**IMPORTANT**: Anda perlu membuat data berlabel terlebih dahulu!\n",
    "\n",
    "1. Export subset komentar dari `data/processed/`\n",
    "2. Ikuti panduan di `data/labelled/LABELING_GUIDE.md`\n",
    "3. Simpan hasil labeling sebagai `labelled_comments.csv`\n",
    "\n",
    "Format yang diharapkan:\n",
    "```\n",
    "comment_id,text,sentiment,emotions,aspects,toxicity,stance,intent\n",
    "1,\"Pelatih harus diganti!\",negatif,\"marah,kecewa\",\"pelatih,strategi\",non-toxic,kontra,komplain\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed378176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labeled data\n",
    "# NOTE: File ini harus Anda buat terlebih dahulu!\n",
    "labeled_file = '../data/labelled/labelled_comments.csv'\n",
    "\n",
    "if not os.path.exists(labeled_file):\n",
    "    print(\"‚ö†Ô∏è  WARNING: File labelled_comments.csv tidak ditemukan!\")\n",
    "    print(\"üìù Silakan buat data berlabel mengikuti panduan di data/labelled/LABELING_GUIDE.md\")\n",
    "    print(\"\\nüí° Untuk demo, saya akan membuat contoh data dummy...\")\n",
    "    \n",
    "    # Create dummy data for demonstration\n",
    "    dummy_data = {\n",
    "        'comment_id': range(1, 21),\n",
    "        'text': [\n",
    "            \"Pelatih harus diganti, strateginya kacau!\",\n",
    "            \"Kapan Indonesia bisa lolos Piala Dunia?\",\n",
    "            \"Mantap performanya, terus semangat!\",\n",
    "            \"PSSI harus lebih profesional dalam manajemen\",\n",
    "            \"Menurut saya latihan harus lebih intensif\",\n",
    "            \"Pemain kurang disiplin di lapangan\",\n",
    "            \"Wasit memihak lawan, tidak adil!\",\n",
    "            \"Supporter Indonesia luar biasa!\",\n",
    "            \"Bagaimana cara daftar jadi pemain timnas?\",\n",
    "            \"Kecewa berat dengan hasil ini\",\n",
    "            \"Semangat terus untuk timnas kita!\",\n",
    "            \"Manajemen PSSI perlu evaluasi menyeluruh\",\n",
    "            \"Strategi pelatih sudah bagus, tinggal eksekusi\",\n",
    "            \"Pemain muda harus diberi kesempatan lebih\",\n",
    "            \"Kenapa tidak panggil pemain dari liga eropa?\",\n",
    "            \"Garuda di dadaku!\",\n",
    "            \"Jangan menyerah, masih ada kesempatan\",\n",
    "            \"Federasi harus mendukung penuh timnas\",\n",
    "            \"Harusnya latih tanding dengan tim kuat\",\n",
    "            \"Bangga dengan perjuangan kalian!\"\n",
    "        ],\n",
    "        'sentiment': ['negatif', 'netral', 'positif', 'netral', 'netral', \n",
    "                     'negatif', 'negatif', 'positif', 'netral', 'negatif',\n",
    "                     'positif', 'negatif', 'positif', 'netral', 'netral',\n",
    "                     'positif', 'positif', 'netral', 'netral', 'positif'],\n",
    "        'emotions': ['marah,kecewa', 'sedih', 'senang,bangga', '', 'sedih',\n",
    "                    'kecewa', 'marah', 'senang', '', 'kecewa,sedih',\n",
    "                    'senang', 'kecewa', 'senang', '', '',\n",
    "                    'bangga', 'senang', '', '', 'bangga,senang'],\n",
    "        'aspects': ['pelatih,strategi', '', 'pemain', 'PSSI,manajemen', 'strategi',\n",
    "                   'pemain', 'wasit', 'fanbase', '', '',\n",
    "                   '', 'PSSI,manajemen', 'pelatih,strategi', 'pemain', '',\n",
    "                   '', '', 'federasi', 'strategi', ''],\n",
    "        'toxicity': ['non-toxic'] * 20,\n",
    "        'stance': ['kontra', 'tidak_jelas', 'pro', 'kontra', 'tidak_jelas',\n",
    "                  'kontra', 'kontra', 'pro', 'tidak_jelas', 'kontra',\n",
    "                  'pro', 'kontra', 'pro', 'tidak_jelas', 'tidak_jelas',\n",
    "                  'pro', 'pro', 'tidak_jelas', 'tidak_jelas', 'pro'],\n",
    "        'intent': ['komplain', 'pertanyaan', 'ajakan', 'saran', 'saran',\n",
    "                  'komplain', 'komplain', 'informasi', 'pertanyaan', 'komplain',\n",
    "                  'ajakan', 'komplain', 'informasi', 'saran', 'pertanyaan',\n",
    "                  'informasi', 'ajakan', 'saran', 'saran', 'informasi']\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(dummy_data)\n",
    "    print(\"‚úÖ Dummy data created for demonstration\")\n",
    "else:\n",
    "    df = pd.read_csv(labeled_file)\n",
    "    print(f\"‚úÖ Loaded {len(df)} labeled comments\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nüìã Sample Data:\")\n",
    "display(df.head())\n",
    "\n",
    "print(f\"\\nüìä Dataset Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f931130",
   "metadata": {},
   "source": [
    "## üîÑ Prepare Data for Training\n",
    "\n",
    "Convert string labels to proper format for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6496165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract texts\n",
    "texts = df['text'].tolist()\n",
    "\n",
    "# Prepare emotion labels (multi-label)\n",
    "emotion_labels = df['emotions'].apply(\n",
    "    lambda x: x.split(',') if pd.notna(x) and x else []\n",
    ").tolist()\n",
    "\n",
    "# Prepare aspect labels (multi-label)\n",
    "aspect_labels = df['aspects'].apply(\n",
    "    lambda x: x.split(',') if pd.notna(x) and x else []\n",
    ").tolist()\n",
    "\n",
    "# Single-label columns\n",
    "toxicity_labels = df['toxicity'].tolist()\n",
    "stance_labels = df['stance'].tolist()\n",
    "intent_labels = df['intent'].tolist()\n",
    "\n",
    "print(\"‚úÖ Data prepared for training\")\n",
    "print(f\"\\nüìä Label Statistics:\")\n",
    "print(f\"- Total texts: {len(texts)}\")\n",
    "print(f\"- Unique emotions: {set([e for sublist in emotion_labels for e in sublist])}\")\n",
    "print(f\"- Unique aspects: {set([a for sublist in aspect_labels for a in sublist])}\")\n",
    "print(f\"- Toxicity distribution: {df['toxicity'].value_counts().to_dict()}\")\n",
    "print(f\"- Stance distribution: {df['stance'].value_counts().to_dict()}\")\n",
    "print(f\"- Intent distribution: {df['intent'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fac938",
   "metadata": {},
   "source": [
    "## üé≠ Train Emotion Classifier (Multi-Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "if layer_config['enable_emotion']:\n",
    "    print(\"üé≠ Training Emotion Classifier...\")\n",
    "    \n",
    "    emotion_clf = EmotionClassifier(\n",
    "        emotion_labels=layer_config['emotion_labels'],\n",
    "        max_features=config['model_parameters']['max_features'],\n",
    "        ngram_range=tuple(config['model_parameters']['ngram_range'])\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    emotion_clf.train(texts, emotion_labels)\n",
    "    \n",
    "    # Evaluate\n",
    "    emotion_metrics = emotion_clf.evaluate(texts, emotion_labels)\n",
    "    \n",
    "    print(\"\\nüìä Emotion Classifier Metrics:\")\n",
    "    print(f\"- Macro Precision: {emotion_metrics['macro_precision']:.4f}\")\n",
    "    print(f\"- Macro Recall: {emotion_metrics['macro_recall']:.4f}\")\n",
    "    print(f\"- Macro F1: {emotion_metrics['macro_f1']:.4f}\")\n",
    "    print(f\"- Hamming Loss: {emotion_metrics['hamming_loss']:.4f}\")\n",
    "    print(f\"- Jaccard Score: {emotion_metrics['jaccard_score']:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    os.makedirs('../models', exist_ok=True)\n",
    "    emotion_clf.save(\n",
    "        '../models/emotion_svm.pkl',\n",
    "        '../models/emotion_vectorizer.pkl',\n",
    "        '../models/emotion_mlb.pkl'\n",
    "    )\n",
    "    save_metrics_json(emotion_metrics, '../models/metrics_emotion.json')\n",
    "    \n",
    "    print(\"‚úÖ Emotion classifier trained and saved!\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Emotion layer disabled in config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c2bb1",
   "metadata": {},
   "source": [
    "## üéØ Train Aspect Classifier (Multi-Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if layer_config['enable_aspect']:\n",
    "    print(\"üéØ Training Aspect Classifier...\")\n",
    "    \n",
    "    aspect_clf = AspectClassifier(\n",
    "        aspect_labels=layer_config['aspect_labels'],\n",
    "        max_features=config['model_parameters']['max_features'],\n",
    "        ngram_range=tuple(config['model_parameters']['ngram_range'])\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    aspect_clf.train(texts, aspect_labels)\n",
    "    \n",
    "    # Evaluate\n",
    "    aspect_metrics = aspect_clf.evaluate(texts, aspect_labels)\n",
    "    \n",
    "    print(\"\\nüìä Aspect Classifier Metrics:\")\n",
    "    print(f\"- Macro Precision: {aspect_metrics['macro_precision']:.4f}\")\n",
    "    print(f\"- Macro Recall: {aspect_metrics['macro_recall']:.4f}\")\n",
    "    print(f\"- Macro F1: {aspect_metrics['macro_f1']:.4f}\")\n",
    "    print(f\"- Hamming Loss: {aspect_metrics['hamming_loss']:.4f}\")\n",
    "    print(f\"- Jaccard Score: {aspect_metrics['jaccard_score']:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    aspect_clf.save(\n",
    "        '../models/aspect_svm.pkl',\n",
    "        '../models/aspect_vectorizer.pkl',\n",
    "        '../models/aspect_mlb.pkl'\n",
    "    )\n",
    "    save_metrics_json(aspect_metrics, '../models/metrics_aspect.json')\n",
    "    \n",
    "    print(\"‚úÖ Aspect classifier trained and saved!\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Aspect layer disabled in config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b494d1",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Train Toxicity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a28c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if layer_config['enable_toxicity']:\n",
    "    print(\"‚ö†Ô∏è  Training Toxicity Classifier...\")\n",
    "    \n",
    "    toxicity_clf = ToxicityClassifier(\n",
    "        max_features=config['model_parameters']['max_features'],\n",
    "        ngram_range=tuple(config['model_parameters']['ngram_range'])\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    toxicity_clf.train(texts, toxicity_labels)\n",
    "    \n",
    "    # Evaluate\n",
    "    toxicity_metrics = toxicity_clf.evaluate(texts, toxicity_labels)\n",
    "    \n",
    "    print(\"\\nüìä Toxicity Classifier Metrics:\")\n",
    "    print(f\"- Accuracy: {toxicity_metrics['accuracy']:.4f}\")\n",
    "    print(f\"- Precision: {toxicity_metrics['precision']:.4f}\")\n",
    "    print(f\"- Recall: {toxicity_metrics['recall']:.4f}\")\n",
    "    print(f\"- F1-Score: {toxicity_metrics['f1_score']:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    toxicity_clf.save(\n",
    "        '../models/toxicity_svm.pkl',\n",
    "        '../models/toxicity_vectorizer.pkl',\n",
    "        '../models/toxicity_encoder.pkl'\n",
    "    )\n",
    "    save_metrics_json(toxicity_metrics, '../models/metrics_toxicity.json')\n",
    "    \n",
    "    print(\"‚úÖ Toxicity classifier trained and saved!\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Toxicity layer disabled in config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa6b3f",
   "metadata": {},
   "source": [
    "## üí≠ Train Stance Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71bf1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if layer_config['enable_stance']:\n",
    "    print(\"üí≠ Training Stance Classifier...\")\n",
    "    \n",
    "    stance_clf = StanceClassifier(\n",
    "        stance_labels=layer_config['stance_labels'],\n",
    "        max_features=config['model_parameters']['max_features'],\n",
    "        ngram_range=tuple(config['model_parameters']['ngram_range'])\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    stance_clf.train(texts, stance_labels)\n",
    "    \n",
    "    # Evaluate\n",
    "    stance_metrics = stance_clf.evaluate(texts, stance_labels)\n",
    "    \n",
    "    print(\"\\nüìä Stance Classifier Metrics:\")\n",
    "    print(f\"- Accuracy: {stance_metrics['accuracy']:.4f}\")\n",
    "    print(f\"- Precision: {stance_metrics['precision']:.4f}\")\n",
    "    print(f\"- Recall: {stance_metrics['recall']:.4f}\")\n",
    "    print(f\"- F1-Score: {stance_metrics['f1_score']:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    stance_clf.save(\n",
    "        '../models/stance_svm.pkl',\n",
    "        '../models/stance_vectorizer.pkl',\n",
    "        '../models/stance_encoder.pkl'\n",
    "    )\n",
    "    save_metrics_json(stance_metrics, '../models/metrics_stance.json')\n",
    "    \n",
    "    print(\"‚úÖ Stance classifier trained and saved!\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Stance layer disabled in config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8e498c",
   "metadata": {},
   "source": [
    "## üìù Train Intent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f474f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "if layer_config['enable_intent']:\n",
    "    print(\"üìù Training Intent Classifier...\")\n",
    "    \n",
    "    intent_clf = IntentClassifier(\n",
    "        intent_labels=layer_config['intent_labels'],\n",
    "        max_features=config['model_parameters']['max_features'],\n",
    "        ngram_range=tuple(config['model_parameters']['ngram_range'])\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    intent_clf.train(texts, intent_labels)\n",
    "    \n",
    "    # Evaluate\n",
    "    intent_metrics = intent_clf.evaluate(texts, intent_labels)\n",
    "    \n",
    "    print(\"\\nüìä Intent Classifier Metrics:\")\n",
    "    print(f\"- Accuracy: {intent_metrics['accuracy']:.4f}\")\n",
    "    print(f\"- Precision: {intent_metrics['precision']:.4f}\")\n",
    "    print(f\"- Recall: {intent_metrics['recall']:.4f}\")\n",
    "    print(f\"- F1-Score: {intent_metrics['f1_score']:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    intent_clf.save(\n",
    "        '../models/intent_svm.pkl',\n",
    "        '../models/intent_vectorizer.pkl',\n",
    "        '../models/intent_encoder.pkl'\n",
    "    )\n",
    "    save_metrics_json(intent_metrics, '../models/metrics_intent.json')\n",
    "    \n",
    "    print(\"‚úÖ Intent classifier trained and saved!\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Intent layer disabled in config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92ba7b",
   "metadata": {},
   "source": [
    "## üîÆ Inference: Predict on New Comments\n",
    "\n",
    "Load trained models and predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e870cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample new comments to predict\n",
    "new_comments = [\n",
    "    \"Pelatih baru harus segera dicari!\",\n",
    "    \"Bangga dengan perjuangan kalian, terus berjuang!\",\n",
    "    \"Kapan timnas kita bisa juara?\",\n",
    "    \"Pemain muda perlu lebih banyak jam terbang\",\n",
    "    \"Kecewa dengan manajemen PSSI yang tidak profesional\"\n",
    "]\n",
    "\n",
    "print(f\"üîÆ Predicting on {len(new_comments)} new comments...\\n\")\n",
    "\n",
    "# Predict from each layer\n",
    "emotion_pred, emotion_conf = emotion_clf.predict(new_comments)\n",
    "aspect_pred, aspect_conf = aspect_clf.predict(new_comments)\n",
    "toxicity_pred, toxicity_scores = toxicity_clf.predict(new_comments)\n",
    "stance_pred, stance_conf = stance_clf.predict(new_comments)\n",
    "intent_pred, intent_conf = intent_clf.predict(new_comments)\n",
    "\n",
    "# For sentiment, we'll use dummy predictions (in real case, load your sentiment model)\n",
    "sentiment_pred = ['negatif', 'positif', 'netral', 'netral', 'negatif']\n",
    "sentiment_conf = np.array([0.85, 0.92, 0.68, 0.73, 0.88])\n",
    "\n",
    "print(\"‚úÖ Predictions complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22e1237",
   "metadata": {},
   "source": [
    "## üìä Create Comprehensive Output DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feecd466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive output\n",
    "output_df = create_layered_output_dataframe(\n",
    "    texts=new_comments,\n",
    "    sentiment_labels=sentiment_pred,\n",
    "    sentiment_confidence=sentiment_conf,\n",
    "    emotion_labels=emotion_pred,\n",
    "    aspect_labels=aspect_pred,\n",
    "    toxicity_labels=toxicity_pred,\n",
    "    toxicity_scores=toxicity_scores,\n",
    "    stance_labels=stance_pred,\n",
    "    stance_confidence=stance_conf,\n",
    "    intent_labels=intent_pred,\n",
    "    intent_confidence=intent_conf,\n",
    "    low_confidence_threshold=layer_config['low_confidence_threshold']\n",
    ")\n",
    "\n",
    "print(\"üìã Layered Predictions Output:\\n\")\n",
    "display(output_df)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = '../data/processed/layered_predictions_demo.csv'\n",
    "output_df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "print(f\"\\n‚úÖ Output saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f4b75",
   "metadata": {},
   "source": [
    "## üìà Visualize Layer Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4c02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentiment distribution\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Sentiment\n",
    "output_df['sentiment'].value_counts().plot(kind='bar', ax=axes[0, 0], color='skyblue')\n",
    "axes[0, 0].set_title('Sentiment Distribution')\n",
    "axes[0, 0].set_xlabel('')\n",
    "\n",
    "# Toxicity\n",
    "output_df['toxicity_label'].value_counts().plot(kind='bar', ax=axes[0, 1], color='coral')\n",
    "axes[0, 1].set_title('Toxicity Distribution')\n",
    "axes[0, 1].set_xlabel('')\n",
    "\n",
    "# Stance\n",
    "output_df['stance'].value_counts().plot(kind='bar', ax=axes[0, 2], color='lightgreen')\n",
    "axes[0, 2].set_title('Stance Distribution')\n",
    "axes[0, 2].set_xlabel('')\n",
    "\n",
    "# Intent\n",
    "output_df['intent'].value_counts().plot(kind='bar', ax=axes[1, 0], color='plum')\n",
    "axes[1, 0].set_title('Intent Distribution')\n",
    "axes[1, 0].set_xlabel('')\n",
    "\n",
    "# Emotions (count all)\n",
    "all_emotions = []\n",
    "for emotions_str in output_df['emotions']:\n",
    "    if pd.notna(emotions_str) and emotions_str:\n",
    "        all_emotions.extend(emotions_str.split(','))\n",
    "        \n",
    "if all_emotions:\n",
    "    pd.Series(all_emotions).value_counts().plot(kind='bar', ax=axes[1, 1], color='gold')\n",
    "    axes[1, 1].set_title('Emotion Distribution (Multi-label)')\n",
    "    axes[1, 1].set_xlabel('')\n",
    "\n",
    "# Aspects (count all)\n",
    "all_aspects = []\n",
    "for aspects_str in output_df['aspects']:\n",
    "    if pd.notna(aspects_str) and aspects_str:\n",
    "        all_aspects.extend(aspects_str.split(','))\n",
    "\n",
    "if all_aspects:\n",
    "    pd.Series(all_aspects).value_counts().plot(kind='bar', ax=axes[1, 2], color='orange')\n",
    "    axes[1, 2].set_title('Aspect Distribution (Multi-label)')\n",
    "    axes[1, 2].set_xlabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/visualizations/layered_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualizations created and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ae65c",
   "metadata": {},
   "source": [
    "## üìù Generate Comprehensive Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive report\n",
    "sentiment_metrics_dummy = {\n",
    "    'accuracy': 0.85,\n",
    "    'precision': 0.83,\n",
    "    'recall': 0.84,\n",
    "    'f1_score': 0.83\n",
    "}\n",
    "\n",
    "report = create_comprehensive_report(\n",
    "    sentiment_metrics=sentiment_metrics_dummy,\n",
    "    emotion_metrics=emotion_metrics if layer_config['enable_emotion'] else None,\n",
    "    aspect_metrics=aspect_metrics if layer_config['enable_aspect'] else None,\n",
    "    toxicity_metrics=toxicity_metrics if layer_config['enable_toxicity'] else None,\n",
    "    stance_metrics=stance_metrics if layer_config['enable_stance'] else None,\n",
    "    intent_metrics=intent_metrics if layer_config['enable_intent'] else None\n",
    ")\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Save report\n",
    "report_path = '../results/reports/layered_analytics_report.txt'\n",
    "os.makedirs('../results/reports', exist_ok=True)\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"\\n‚úÖ Report saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af57a16e",
   "metadata": {},
   "source": [
    "## üéâ Summary\n",
    "\n",
    "### What We've Accomplished:\n",
    "\n",
    "1. ‚úÖ **Trained 5 Layer Classifiers**\n",
    "   - Emotion (multi-label)\n",
    "   - Aspect (multi-label)\n",
    "   - Toxicity (binary)\n",
    "   - Stance (3-class)\n",
    "   - Intent (6-class)\n",
    "\n",
    "2. ‚úÖ **Evaluated Each Layer**\n",
    "   - Single-label: Accuracy, Precision, Recall, F1\n",
    "   - Multi-label: Macro metrics, Hamming loss, Jaccard score\n",
    "\n",
    "3. ‚úÖ **Saved All Artifacts**\n",
    "   - Models: `models/*_svm.pkl`\n",
    "   - Vectorizers: `models/*_vectorizer.pkl`\n",
    "   - Encoders: `models/*_encoder.pkl` / `*_mlb.pkl`\n",
    "   - Metrics: `models/metrics_*.json`\n",
    "\n",
    "4. ‚úÖ **Created Comprehensive Output**\n",
    "   - CSV with all layer predictions\n",
    "   - Confidence scores per layer\n",
    "   - Low confidence flags\n",
    "\n",
    "5. ‚úÖ **Generated Visualizations**\n",
    "   - Distribution per layer\n",
    "   - Saved to `results/visualizations/`\n",
    "\n",
    "6. ‚úÖ **Generated Report**\n",
    "   - Comprehensive metrics across all layers\n",
    "   - Saved to `results/reports/`\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Label More Data**: Increase training set size (target 300-500 per class)\n",
    "2. **Tune Thresholds**: Adjust confidence/toxicity thresholds\n",
    "3. **Integrate with Main Pipeline**: Add layered analytics to production workflow\n",
    "4. **Deploy**: Create API endpoint or dashboard\n",
    "5. **Monitor**: Track performance on new data\n",
    "\n",
    "---\n",
    "\n",
    "**üöÄ Your multi-layer analytics system is ready!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
