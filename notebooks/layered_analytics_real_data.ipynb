{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f7513d",
   "metadata": {},
   "source": [
    "# ğŸ¯ Multi-Layer Analytics - Real Data Demo\n",
    "\n",
    "Demo training dan inference menggunakan **data real** dari dataset timnas.\n",
    "\n",
    "**Layers:**\n",
    "- ğŸ˜Š Emotion (multi-label): marah, kecewa, sedih, senang, bangga, takut\n",
    "- ğŸ¯ Aspect (multi-label): manajemen, pelatih, pemain, strategi, wasit, PSSI, federasi, fanbase\n",
    "- âš ï¸ Toxicity (binary): toxic, non-toxic\n",
    "- ğŸ”€ Stance (3-class): pro, kontra, tidak_jelas\n",
    "- ğŸ’¬ Intent (6-class): pertanyaan, komplain, saran, ajakan, humor, informasi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e0c3e6",
   "metadata": {},
   "source": [
    "## 1. Setup & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import layered classifiers\n",
    "from layered_classifier import (\n",
    "    EmotionClassifier,\n",
    "    AspectClassifier,\n",
    "    ToxicityClassifier,\n",
    "    StanceClassifier,\n",
    "    IntentClassifier\n",
    ")\n",
    "\n",
    "# Import utilities\n",
    "from utils.layered_utils import (\n",
    "    create_layered_output_dataframe,\n",
    "    create_comprehensive_report,\n",
    "    plot_label_distribution,\n",
    "    multilabel_to_string,\n",
    "    string_to_multilabel\n",
    ")\n",
    "\n",
    "print(\"âœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f3bac1",
   "metadata": {},
   "source": [
    "## 2. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab22774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config_path = Path('../config.yaml')\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "layered_config = config['layered_analytics']\n",
    "print(\"ğŸ“‹ Configuration loaded:\")\n",
    "print(f\"  - Emotion labels: {layered_config['emotion_labels']}\")\n",
    "print(f\"  - Aspect labels: {layered_config['aspect_labels']}\")\n",
    "print(f\"  - Stance labels: {layered_config['stance_labels']}\")\n",
    "print(f\"  - Intent labels: {layered_config['intent_labels']}\")\n",
    "print(f\"  - Low confidence threshold: {layered_config['low_confidence_threshold']}\")\n",
    "print(f\"  - Toxicity threshold: {layered_config['toxicity_threshold']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fae68f",
   "metadata": {},
   "source": [
    "## 3. Load Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b09787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed real data\n",
    "data_path = Path('../data/processed/final_processed_dataset_real.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"ğŸ“Š Data loaded: {len(df)} comments\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nSentiment distribution:\")\n",
    "print(df['sentiment_auto'].value_counts())\n",
    "\n",
    "# Preview data\n",
    "print(\"\\nğŸ“ Sample comments:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc15020",
   "metadata": {},
   "source": [
    "## 4. Generate Dummy Labels untuk Demo\n",
    "\n",
    "**Note:** Untuk production, labels harus di-label manual mengikuti `data/labelled/LABELING_GUIDE.md`.\n",
    "\n",
    "Untuk demo ini, kita generate dummy labels based on sentiment dan keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401bed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dummy_labels(df):\n",
    "    \"\"\"\n",
    "    Generate dummy labels untuk demo purposes.\n",
    "    UNTUK PRODUCTION: Label manual menggunakan LABELING_GUIDE.md!\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Emotion labels (multi-label) based on sentiment + keywords\n",
    "    emotions = []\n",
    "    for idx, row in df.iterrows():\n",
    "        text = row['text_cleaned'].lower()\n",
    "        sent = row['sentiment_auto']\n",
    "        \n",
    "        emotion_list = []\n",
    "        if sent == 'negatif':\n",
    "            if any(word in text for word in ['kecewa', 'buruk', 'gagal']):\n",
    "                emotion_list.append('kecewa')\n",
    "            if any(word in text for word in ['bodoh', 'payah', 'berantakan']):\n",
    "                emotion_list.append('marah')\n",
    "            if any(word in text for word in ['sedih', 'menyedihkan']):\n",
    "                emotion_list.append('sedih')\n",
    "        elif sent == 'positif':\n",
    "            if any(word in text for word in ['bangga', 'hebat', 'luar biasa', 'salut']):\n",
    "                emotion_list.append('bangga')\n",
    "            if any(word in text for word in ['senang', 'semangat']):\n",
    "                emotion_list.append('senang')\n",
    "        \n",
    "        if not emotion_list:  # default\n",
    "            emotion_list = ['senang'] if sent == 'positif' else ['kecewa'] if sent == 'negatif' else ['senang']\n",
    "        \n",
    "        emotions.append(emotion_list)\n",
    "    \n",
    "    df['emotions'] = emotions\n",
    "    \n",
    "    # Aspect labels (multi-label) based on keywords\n",
    "    aspects = []\n",
    "    for idx, row in df.iterrows():\n",
    "        text = row['text_cleaned'].lower()\n",
    "        aspect_list = []\n",
    "        \n",
    "        if any(word in text for word in ['manajemen', 'pssi', 'berantakan']):\n",
    "            aspect_list.append('manajemen')\n",
    "        if any(word in text for word in ['pelatih', 'shin', 'tae-yong', 'coach']):\n",
    "            aspect_list.append('pelatih')\n",
    "        if any(word in text for word in ['pemain', 'timnas', 'anak bangsa']):\n",
    "            aspect_list.append('pemain')\n",
    "        if any(word in text for word in ['strategi', 'defensif', 'menyerang']):\n",
    "            aspect_list.append('strategi')\n",
    "        if any(word in text for word in ['pssi']):\n",
    "            aspect_list.append('PSSI')\n",
    "        \n",
    "        if not aspect_list:  # default\n",
    "            aspect_list = ['pemain']\n",
    "        \n",
    "        aspects.append(aspect_list)\n",
    "    \n",
    "    df['aspects'] = aspects\n",
    "    \n",
    "    # Toxicity (binary) - detect offensive language\n",
    "    toxic_keywords = ['bodoh', 'payah', 'berantakan', 'buruk sekali']\n",
    "    df['toxicity_label'] = df['text_cleaned'].apply(\n",
    "        lambda x: 'toxic' if any(word in x.lower() for word in toxic_keywords) else 'non-toxic'\n",
    "    )\n",
    "    \n",
    "    # Stance (3-class) based on sentiment\n",
    "    stance_map = {\n",
    "        'positif': 'pro',\n",
    "        'negatif': 'kontra',\n",
    "        'netral': 'tidak_jelas'\n",
    "    }\n",
    "    df['stance'] = df['sentiment_auto'].map(stance_map)\n",
    "    \n",
    "    # Intent (6-class) based on patterns\n",
    "    intents = []\n",
    "    for idx, row in df.iterrows():\n",
    "        text = row['text_cleaned'].lower()\n",
    "        sent = row['sentiment_auto']\n",
    "        \n",
    "        if '?' in text:\n",
    "            intent = 'pertanyaan'\n",
    "        elif sent == 'negatif' and any(word in text for word in ['harus', 'kurang', 'buruk']):\n",
    "            intent = 'komplain'\n",
    "        elif any(word in text for word in ['evaluasi', 'belajar', 'semangat']):\n",
    "            intent = 'saran'\n",
    "        elif any(word in text for word in ['dukung', 'ayo', 'tetap']):\n",
    "            intent = 'ajakan'\n",
    "        elif sent == 'positif':\n",
    "            intent = 'informasi'\n",
    "        else:\n",
    "            intent = 'informasi'\n",
    "        \n",
    "        intents.append(intent)\n",
    "    \n",
    "    df['intent'] = intents\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate dummy labels\n",
    "df_labelled = generate_dummy_labels(df)\n",
    "\n",
    "print(\"âœ… Dummy labels generated!\")\n",
    "print(\"\\nâš ï¸ REMINDER: Untuk production, gunakan manual labeling dengan LABELING_GUIDE.md\")\n",
    "print(\"\\nğŸ“Š Label distribution:\")\n",
    "print(f\"\\nEmotion: {df_labelled['emotions'].value_counts().head()}\")\n",
    "print(f\"\\nAspect: {df_labelled['aspects'].value_counts().head()}\")\n",
    "print(f\"\\nToxicity:\\n{df_labelled['toxicity_label'].value_counts()}\")\n",
    "print(f\"\\nStance:\\n{df_labelled['stance'].value_counts()}\")\n",
    "print(f\"\\nIntent:\\n{df_labelled['intent'].value_counts()}\")\n",
    "\n",
    "# Preview labelled data\n",
    "df_labelled[['text_cleaned', 'sentiment_auto', 'emotions', 'aspects', 'toxicity_label', 'stance', 'intent']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0c47ef",
   "metadata": {},
   "source": [
    "## 5. Prepare Training Data\n",
    "\n",
    "Dengan data terbatas (7 samples), kita akan:\n",
    "- Train pada semua data (no test split karena terlalu sedikit)\n",
    "- Evaluate pada training set untuk demonstrasi\n",
    "- **Untuk production:** Butuh minimal 300-500 samples per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all data for training (karena dataset kecil)\n",
    "X_train = df_labelled['text_cleaned'].values\n",
    "X_test = X_train  # Same data untuk evaluation demo\n",
    "\n",
    "print(f\"ğŸ“Š Training samples: {len(X_train)}\")\n",
    "print(f\"ğŸ“Š Test samples: {len(X_test)} (same as train for demo)\")\n",
    "print(\"\\nâš ï¸ Production note: Split 80/20 dengan dataset >= 500 samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ab45e0",
   "metadata": {},
   "source": [
    "## 6. Train Layer 1: Emotion Classifier (Multi-Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5516f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare emotion labels\n",
    "y_train_emotion = df_labelled['emotions'].values\n",
    "y_test_emotion = y_train_emotion\n",
    "\n",
    "# Initialize and train\n",
    "emotion_clf = EmotionClassifier(\n",
    "    emotion_labels=layered_config['emotion_labels'],\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "print(\"ğŸ”„ Training Emotion Classifier...\")\n",
    "emotion_clf.train(X_train, y_train_emotion)\n",
    "\n",
    "# Evaluate\n",
    "metrics = emotion_clf.evaluate(X_test, y_test_emotion)\n",
    "print(\"\\nâœ… Emotion Classifier trained!\")\n",
    "print(f\"\\nğŸ“Š Metrics:\")\n",
    "print(f\"  - Macro F1: {metrics['macro_f1']:.3f}\")\n",
    "print(f\"  - Hamming Loss: {metrics['hamming_loss']:.3f}\")\n",
    "print(f\"  - Jaccard Score: {metrics['jaccard_score']:.3f}\")\n",
    "\n",
    "# Save model\n",
    "model_path = '../models/emotion_classifier.pkl'\n",
    "emotion_clf.save(model_path)\n",
    "print(f\"\\nğŸ’¾ Model saved: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7867c3e",
   "metadata": {},
   "source": [
    "## 7. Train Layer 2: Aspect Classifier (Multi-Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade87bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare aspect labels\n",
    "y_train_aspect = df_labelled['aspects'].values\n",
    "y_test_aspect = y_train_aspect\n",
    "\n",
    "# Initialize and train\n",
    "aspect_clf = AspectClassifier(\n",
    "    aspect_labels=layered_config['aspect_labels'],\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "print(\"ğŸ”„ Training Aspect Classifier...\")\n",
    "aspect_clf.train(X_train, y_train_aspect)\n",
    "\n",
    "# Evaluate\n",
    "metrics = aspect_clf.evaluate(X_test, y_test_aspect)\n",
    "print(\"\\nâœ… Aspect Classifier trained!\")\n",
    "print(f\"\\nğŸ“Š Metrics:\")\n",
    "print(f\"  - Macro F1: {metrics['macro_f1']:.3f}\")\n",
    "print(f\"  - Hamming Loss: {metrics['hamming_loss']:.3f}\")\n",
    "print(f\"  - Jaccard Score: {metrics['jaccard_score']:.3f}\")\n",
    "\n",
    "# Save model\n",
    "model_path = '../models/aspect_classifier.pkl'\n",
    "aspect_clf.save(model_path)\n",
    "print(f\"\\nğŸ’¾ Model saved: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1baa7b",
   "metadata": {},
   "source": [
    "## 8. Train Layer 3: Toxicity Classifier (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare toxicity labels\n",
    "y_train_toxicity = df_labelled['toxicity_label'].values\n",
    "y_test_toxicity = y_train_toxicity\n",
    "\n",
    "# Initialize and train\n",
    "toxicity_clf = ToxicityClassifier(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "print(\"ğŸ”„ Training Toxicity Classifier...\")\n",
    "toxicity_clf.train(X_train, y_train_toxicity)\n",
    "\n",
    "# Evaluate\n",
    "metrics = toxicity_clf.evaluate(X_test, y_test_toxicity)\n",
    "print(\"\\nâœ… Toxicity Classifier trained!\")\n",
    "print(f\"\\nğŸ“Š Metrics:\")\n",
    "print(f\"  - Accuracy: {metrics['accuracy']:.3f}\")\n",
    "print(f\"  - Precision: {metrics['precision']:.3f}\")\n",
    "print(f\"  - Recall: {metrics['recall']:.3f}\")\n",
    "print(f\"  - F1: {metrics['f1']:.3f}\")\n",
    "\n",
    "# Save model\n",
    "model_path = '../models/toxicity_classifier.pkl'\n",
    "toxicity_clf.save(model_path)\n",
    "print(f\"\\nğŸ’¾ Model saved: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0403cb65",
   "metadata": {},
   "source": [
    "## 9. Train Layer 4: Stance Classifier (3-Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d33392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare stance labels\n",
    "y_train_stance = df_labelled['stance'].values\n",
    "y_test_stance = y_train_stance\n",
    "\n",
    "# Initialize and train\n",
    "stance_clf = StanceClassifier(\n",
    "    stance_labels=layered_config['stance_labels'],\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "print(\"ğŸ”„ Training Stance Classifier...\")\n",
    "stance_clf.train(X_train, y_train_stance)\n",
    "\n",
    "# Evaluate\n",
    "metrics = stance_clf.evaluate(X_test, y_test_stance)\n",
    "print(\"\\nâœ… Stance Classifier trained!\")\n",
    "print(f\"\\nğŸ“Š Metrics:\")\n",
    "print(f\"  - Accuracy: {metrics['accuracy']:.3f}\")\n",
    "print(f\"  - Macro Precision: {metrics['macro_precision']:.3f}\")\n",
    "print(f\"  - Macro Recall: {metrics['macro_recall']:.3f}\")\n",
    "print(f\"  - Macro F1: {metrics['macro_f1']:.3f}\")\n",
    "\n",
    "# Save model\n",
    "model_path = '../models/stance_classifier.pkl'\n",
    "stance_clf.save(model_path)\n",
    "print(f\"\\nğŸ’¾ Model saved: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b0a27e",
   "metadata": {},
   "source": [
    "## 10. Train Layer 5: Intent Classifier (6-Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400aac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare intent labels\n",
    "y_train_intent = df_labelled['intent'].values\n",
    "y_test_intent = y_train_intent\n",
    "\n",
    "# Initialize and train\n",
    "intent_clf = IntentClassifier(\n",
    "    intent_labels=layered_config['intent_labels'],\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "print(\"ğŸ”„ Training Intent Classifier...\")\n",
    "intent_clf.train(X_train, y_train_intent)\n",
    "\n",
    "# Evaluate\n",
    "metrics = intent_clf.evaluate(X_test, y_test_intent)\n",
    "print(\"\\nâœ… Intent Classifier trained!\")\n",
    "print(f\"\\nğŸ“Š Metrics:\")\n",
    "print(f\"  - Accuracy: {metrics['accuracy']:.3f}\")\n",
    "print(f\"  - Macro Precision: {metrics['macro_precision']:.3f}\")\n",
    "print(f\"  - Macro Recall: {metrics['macro_recall']:.3f}\")\n",
    "print(f\"  - Macro F1: {metrics['macro_f1']:.3f}\")\n",
    "\n",
    "# Save model\n",
    "model_path = '../models/intent_classifier.pkl'\n",
    "intent_clf.save(model_path)\n",
    "print(f\"\\nğŸ’¾ Model saved: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1b27bc",
   "metadata": {},
   "source": [
    "## 11. Inference: Apply All Layers pada Data Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from all layers\n",
    "texts = df['text_cleaned'].values\n",
    "\n",
    "print(\"ğŸ”„ Applying all layers...\\n\")\n",
    "\n",
    "# Layer 1: Emotion\n",
    "emotion_preds, emotion_probs = emotion_clf.predict(texts, return_probabilities=True)\n",
    "print(\"âœ… Emotion predictions done\")\n",
    "\n",
    "# Layer 2: Aspect\n",
    "aspect_preds, aspect_probs = aspect_clf.predict(texts, return_probabilities=True)\n",
    "print(\"âœ… Aspect predictions done\")\n",
    "\n",
    "# Layer 3: Toxicity\n",
    "toxicity_labels, toxicity_scores = toxicity_clf.predict(texts, return_scores=True)\n",
    "print(\"âœ… Toxicity predictions done\")\n",
    "\n",
    "# Layer 4: Stance\n",
    "stance_preds, stance_probs = stance_clf.predict(texts, return_probabilities=True)\n",
    "print(\"âœ… Stance predictions done\")\n",
    "\n",
    "# Layer 5: Intent\n",
    "intent_preds, intent_probs = intent_clf.predict(texts, return_probabilities=True)\n",
    "print(\"âœ… Intent predictions done\")\n",
    "\n",
    "print(\"\\nğŸ‰ All layers applied successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904127c",
   "metadata": {},
   "source": [
    "## 12. Create Comprehensive Output DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c96c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare predictions dictionary\n",
    "predictions = {\n",
    "    'emotion': emotion_preds,\n",
    "    'emotion_probs': emotion_probs,\n",
    "    'aspect': aspect_preds,\n",
    "    'aspect_probs': aspect_probs,\n",
    "    'toxicity': toxicity_labels,\n",
    "    'toxicity_scores': toxicity_scores,\n",
    "    'stance': stance_preds,\n",
    "    'stance_probs': stance_probs,\n",
    "    'intent': intent_preds,\n",
    "    'intent_probs': intent_probs\n",
    "}\n",
    "\n",
    "# Create comprehensive dataframe\n",
    "output_df = create_layered_output_dataframe(\n",
    "    texts=texts,\n",
    "    sentiment_labels=df['sentiment_auto'].values,\n",
    "    sentiment_probs=df['sentiment_score'].values,\n",
    "    predictions=predictions,\n",
    "    low_conf_threshold=layered_config['low_confidence_threshold'],\n",
    "    toxicity_threshold=layered_config['toxicity_threshold']\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Š Comprehensive Output DataFrame:\")\n",
    "print(f\"Shape: {output_df.shape}\")\n",
    "print(f\"\\nColumns: {output_df.columns.tolist()}\")\n",
    "\n",
    "# Display output\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4c2cb2",
   "metadata": {},
   "source": [
    "## 13. Detailed View: Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detailed predictions for first 3 comments\n",
    "print(\"ğŸ” Detailed Predictions:\\n\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for idx in range(min(3, len(output_df))):\n",
    "    row = output_df.iloc[idx]\n",
    "    print(f\"\\nğŸ“ Comment #{idx+1}:\")\n",
    "    print(f\"Text: {row['text'][:80]}...\" if len(row['text']) > 80 else f\"Text: {row['text']}\")\n",
    "    print(f\"\\nğŸ­ Sentiment: {row['sentiment']} (confidence: {row['sentiment_confidence']:.3f})\")\n",
    "    print(f\"ğŸ˜Š Emotions: {row['emotions']}\")\n",
    "    print(f\"ğŸ¯ Aspects: {row['aspects']}\")\n",
    "    print(f\"âš ï¸ Toxicity: {row['toxicity_label']} (score: {row['toxicity_score']:.3f})\")\n",
    "    print(f\"ğŸ”€ Stance: {row['stance']} (confidence: {row['stance_confidence']:.3f})\")\n",
    "    print(f\"ğŸ’¬ Intent: {row['intent']} (confidence: {row['intent_confidence']:.3f})\")\n",
    "    print(f\"ğŸš© Low Confidence? {row['low_confidence_flag']}\")\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d74540",
   "metadata": {},
   "source": [
    "## 14. Save Predictions to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d95e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "output_path = '../data/processed/layered_predictions_real.csv'\n",
    "output_df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"âœ… Predictions saved to: {output_path}\")\n",
    "print(f\"ğŸ“Š Total predictions: {len(output_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4c09ff",
   "metadata": {},
   "source": [
    "## 15. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7aedd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('ğŸ¯ Multi-Layer Analytics - Real Data Results', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Sentiment distribution\n",
    "sentiment_counts = output_df['sentiment'].value_counts()\n",
    "axes[0, 0].bar(sentiment_counts.index, sentiment_counts.values, color=['green', 'gray', 'red'])\n",
    "axes[0, 0].set_title('ğŸ­ Sentiment Distribution')\n",
    "axes[0, 0].set_xlabel('Sentiment')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "\n",
    "# 2. Emotion distribution (split multi-label)\n",
    "emotion_split = output_df['emotions'].str.split(',').explode().str.strip()\n",
    "emotion_counts = emotion_split.value_counts()\n",
    "axes[0, 1].barh(emotion_counts.index, emotion_counts.values)\n",
    "axes[0, 1].set_title('ğŸ˜Š Emotion Distribution')\n",
    "axes[0, 1].set_xlabel('Count')\n",
    "\n",
    "# 3. Aspect distribution (split multi-label)\n",
    "aspect_split = output_df['aspects'].str.split(',').explode().str.strip()\n",
    "aspect_counts = aspect_split.value_counts()\n",
    "axes[0, 2].barh(aspect_counts.index, aspect_counts.values, color='orange')\n",
    "axes[0, 2].set_title('ğŸ¯ Aspect Distribution')\n",
    "axes[0, 2].set_xlabel('Count')\n",
    "\n",
    "# 4. Toxicity distribution\n",
    "toxicity_counts = output_df['toxicity_label'].value_counts()\n",
    "colors_tox = ['red' if x == 'toxic' else 'green' for x in toxicity_counts.index]\n",
    "axes[1, 0].pie(toxicity_counts.values, labels=toxicity_counts.index, autopct='%1.1f%%', colors=colors_tox)\n",
    "axes[1, 0].set_title('âš ï¸ Toxicity Distribution')\n",
    "\n",
    "# 5. Stance distribution\n",
    "stance_counts = output_df['stance'].value_counts()\n",
    "axes[1, 1].bar(stance_counts.index, stance_counts.values, color=['blue', 'red', 'gray'])\n",
    "axes[1, 1].set_title('ğŸ”€ Stance Distribution')\n",
    "axes[1, 1].set_xlabel('Stance')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 6. Intent distribution\n",
    "intent_counts = output_df['intent'].value_counts()\n",
    "axes[1, 2].barh(intent_counts.index, intent_counts.values, color='purple')\n",
    "axes[1, 2].set_title('ğŸ’¬ Intent Distribution')\n",
    "axes[1, 2].set_xlabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/visualizations/layered_analytics_real_data.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Visualization saved to: ../results/visualizations/layered_analytics_real_data.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fd5572",
   "metadata": {},
   "source": [
    "## 16. Generate Comprehensive Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc55ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive text report\n",
    "report = create_comprehensive_report(\n",
    "    output_df=output_df,\n",
    "    original_df=df,\n",
    "    include_temporal=False,  # No timestamp in dataset\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "# Save report\n",
    "report_path = '../results/reports/layered_analytics_real_data_report.txt'\n",
    "os.makedirs(os.path.dirname(report_path), exist_ok=True)\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"ğŸ“„ Comprehensive Report:\")\n",
    "print(\"=\"*100)\n",
    "print(report)\n",
    "print(\"=\"*100)\n",
    "print(f\"\\nâœ… Report saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb414a8",
   "metadata": {},
   "source": [
    "## 17. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5828b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ‰ \" + \"=\"*100)\n",
    "print(\"   MULTI-LAYER ANALYTICS COMPLETED!\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\\nâœ… What was done:\")\n",
    "print(\"  1. âœ… Loaded real data (7 comments)\")\n",
    "print(\"  2. âœ… Generated dummy labels for demo\")\n",
    "print(\"  3. âœ… Trained 5 layer classifiers:\")\n",
    "print(\"     - Emotion (multi-label, 6 classes)\")\n",
    "print(\"     - Aspect (multi-label, 8 classes)\")\n",
    "print(\"     - Toxicity (binary)\")\n",
    "print(\"     - Stance (3-class)\")\n",
    "print(\"     - Intent (6-class)\")\n",
    "print(\"  4. âœ… Applied all layers on real data\")\n",
    "print(\"  5. âœ… Generated comprehensive output CSV\")\n",
    "print(\"  6. âœ… Created visualizations\")\n",
    "print(\"  7. âœ… Generated comprehensive report\")\n",
    "\n",
    "print(\"\\nğŸ“¦ Deliverables:\")\n",
    "print(\"  - Models: ../models/*.pkl (5 classifiers)\")\n",
    "print(\"  - Predictions: ../data/processed/layered_predictions_real.csv\")\n",
    "print(\"  - Visualization: ../results/visualizations/layered_analytics_real_data.png\")\n",
    "print(\"  - Report: ../results/reports/layered_analytics_real_data_report.txt\")\n",
    "\n",
    "print(\"\\nâš ï¸ IMPORTANT - Next Steps for Production:\")\n",
    "print(\"  1. ğŸ“ Label more data (300-500 samples per class)\")\n",
    "print(\"     - Follow: data/labelled/LABELING_GUIDE.md\")\n",
    "print(\"     - Use template: data/labelled/labelled_comments_template.csv\")\n",
    "\n",
    "print(\"\\n  2. ğŸ”„ Retrain with labeled data:\")\n",
    "print(\"     - Load labelled_comments.csv\")\n",
    "print(\"     - Split 80/20 train/test\")\n",
    "print(\"     - Train all layers\")\n",
    "print(\"     - Validate on test set\")\n",
    "\n",
    "print(\"\\n  3. ğŸš€ Deploy:\")\n",
    "print(\"     - Integrate dengan existing sentiment pipeline\")\n",
    "print(\"     - Create Streamlit dashboard\")\n",
    "print(\"     - Setup real-time monitoring\")\n",
    "\n",
    "print(\"\\n  4. ğŸ“Š Analyze & Iterate:\")\n",
    "print(\"     - Collect feedback\")\n",
    "print(\"     - Tune thresholds\")\n",
    "print(\"     - Expand training data\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Quick commands:\")\n",
    "print(\"  - Load saved model: clf = EmotionClassifier.load('path/to/model.pkl')\")\n",
    "print(\"  - Predict new text: labels, probs = clf.predict(['new comment'])\")\n",
    "print(\"  - Update config: Edit config.yaml then reload\")\n",
    "\n",
    "print(\"\\nğŸ“ Documentation:\")\n",
    "print(\"  - Quick Start: ../QUICKSTART_LAYERED.md\")\n",
    "print(\"  - Full Docs: ../README.md\")\n",
    "print(\"  - Project Summary: ../SUMMARY_LAYERED.md\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
