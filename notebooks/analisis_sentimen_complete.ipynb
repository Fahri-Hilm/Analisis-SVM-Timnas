{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Analisis Sentimen Publik terhadap Isu \"Indonesia Gagal Lolos Piala Dunia\"\n",
    "\n",
    "**Proyek Data Mining - Analisis Sentimen menggunakan Support Vector Machine (SVM)**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Tujuan Penelitian\n",
    "- Menganalisis persepsi publik terhadap kegagalan Indonesia lolos Piala Dunia melalui komentar YouTube\n",
    "- Mengimplementasikan model SVM untuk klasifikasi sentimen otomatis\n",
    "- Memberikan insight tentang pola sentimen dan kata kunci dominan\n",
    "\n",
    "## üìù Metodologi\n",
    "- **Sumber Data**: Komentar YouTube dari video terkait timnas Indonesia\n",
    "- **Preprocessing**: Text cleaning, normalisasi bahasa Indonesia, TF-IDF vectorization\n",
    "- **Model**: Support Vector Machine (SVM) dengan kernel RBF\n",
    "- **Evaluasi**: Accuracy, Precision, Recall, F1-Score, Confusion Matrix\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Import Libraries dan Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 1. Data Collection dari YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import custom modules\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "sys.path.append('..')  # Add parent directory for config\n",
    "\n",
    "from data_collector import YouTubeDataCollector\n",
    "from preprocessor import IndonesianTextPreprocessor\n",
    "from model import SentimentSVMModel\n",
    "from config import Config\n",
    "\n",
    "print(\"‚úÖ Custom modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize YouTube data collector\n",
    "collector = YouTubeDataCollector()\n",
    "\n",
    "print(\"üéØ Target Keywords:\")\n",
    "for i, keyword in enumerate(Config.SEARCH_KEYWORDS, 1):\n",
    "    print(f\"{i}. {keyword}\")\n",
    "\n",
    "print(f\"\\nüìä Collection Settings:\")\n",
    "print(f\"- Videos per query: {Config.MAX_VIDEOS_PER_QUERY}\")\n",
    "print(f\"- Comments per video: {Config.MAX_COMMENTS_PER_VIDEO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ 4. Model Training dengan SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize SVM model\n",
    "svm_model = SentimentSVMModel(\n",
    "    kernel=Config.SVM_KERNEL,\n",
    "    C=Config.SVM_C,\n",
    "    gamma=Config.SVM_GAMMA\n",
    ")\n",
    "\n",
    "print(\"ü§ñ SVM Model Configuration:\")\n",
    "print(f\"- Kernel: {Config.SVM_KERNEL}\")\n",
    "print(f\"- C (Regularization): {Config.SVM_C}\")\n",
    "print(f\"- Gamma: {Config.SVM_GAMMA}\")\n",
    "print(f\"- Max Features: {Config.MAX_FEATURES}\")\n",
    "print(f\"- N-gram Range: {Config.NGRAM_RANGE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display detailed classification report\n",
    "print(\"üìã Detailed Classification Report:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "class_report = training_results['classification_report']\n",
    "classes = svm_model.label_encoder.classes_\n",
    "\n",
    "# Create classification report DataFrame\n",
    "report_df = pd.DataFrame({\n",
    "    'Class': classes,\n",
    "    'Precision': [class_report[cls]['precision'] for cls in classes],\n",
    "    'Recall': [class_report[cls]['recall'] for cls in classes],\n",
    "    'F1-Score': [class_report[cls]['f1-score'] for cls in classes],\n",
    "    'Support': [class_report[cls]['support'] for cls in classes]\n",
    "})\n",
    "\n",
    "display(report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ 9. Save Model dan Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save trained model and export results\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save the trained SVM model\n",
    "model_filename = '../models/sentiment_svm_model_real_data.pkl'\n",
    "joblib.dump(svm_classifier, model_filename)\n",
    "print(f\"‚úÖ SVM Model saved to: {model_filename}\")\n",
    "\n",
    "# Save the vectorizer\n",
    "vectorizer_filename = '../models/tfidf_vectorizer_real_data.pkl'\n",
    "joblib.dump(vectorizer, vectorizer_filename)\n",
    "print(f\"‚úÖ TF-IDF Vectorizer saved to: {vectorizer_filename}\")\n",
    "\n",
    "# Save the label encoder\n",
    "encoder_filename = '../models/label_encoder_real_data.pkl'\n",
    "joblib.dump(label_encoder, encoder_filename)\n",
    "print(f\"‚úÖ Label Encoder saved to: {encoder_filename}\")\n",
    "\n",
    "# Save processed dataset\n",
    "processed_filename = '../data/processed/final_processed_dataset_real.csv'\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "processed_df.to_csv(processed_filename, index=False)\n",
    "print(f\"‚úÖ Processed dataset saved to: {processed_filename}\")\n",
    "\n",
    "# Save predictions on sample data\n",
    "sample_predictions = pd.DataFrame({\n",
    "    'text': test_comments,\n",
    "    'predicted_sentiment': [label_encoder.classes_[pred] for pred in predictions],\n",
    "    'confidence_negatif': probabilities[:, 0],\n",
    "    'confidence_netral': probabilities[:, 1],\n",
    "    'confidence_positif': probabilities[:, 2]\n",
    "})\n",
    "\n",
    "predictions_filename = '../data/processed/sample_predictions_real.csv'\n",
    "sample_predictions.to_csv(predictions_filename, index=False)\n",
    "print(f\"‚úÖ Sample predictions saved to: {predictions_filename}\")\n",
    "\n",
    "# Save model performance metrics\n",
    "performance_metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1,\n",
    "    'cv_mean': cv_scores.mean(),\n",
    "    'cv_std': cv_scores.std(),\n",
    "    'cv_scores': cv_scores.tolist(),\n",
    "    'dataset_size': len(processed_df),\n",
    "    'n_features': X.shape[1],\n",
    "    'sentiment_distribution': sentiment_dist.to_dict()\n",
    "}\n",
    "\n",
    "metrics_filename = '../models/model_performance_metrics.json'\n",
    "import json\n",
    "with open(metrics_filename, 'w') as f:\n",
    "    json.dump(performance_metrics, f, indent=2)\n",
    "print(f\"‚úÖ Performance metrics saved to: {metrics_filename}\")\n",
    "\n",
    "print(f\"\\nüìÅ ALL FILES SAVED SUCCESSFULLY!\")\n",
    "print(f\"üìä Model artifacts ready for deployment and future use.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù 10. Kesimpulan dan Rekomendasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate final summary report for real data analysis\n",
    "print(\"üìã LAPORAN AKHIR ANALISIS SENTIMEN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Dataset summary\n",
    "print(f\"\\nüìä RINGKASAN DATASET REAL:\")\n",
    "print(f\"- Total komentar yang dianalisis: {len(processed_df):,}\")\n",
    "print(f\"- Periode data: {processed_df['published_date'].min().date()} hingga {processed_df['published_date'].max().date()}\")\n",
    "print(f\"- Total video sumber: {processed_df['video_id'].nunique()}\")\n",
    "print(f\"- Total channel: {processed_df['channel_title'].nunique()}\")\n",
    "\n",
    "# Sentiment distribution\n",
    "sentiment_dist = processed_df['sentiment_auto'].value_counts(normalize=True) * 100\n",
    "print(f\"\\nüéØ DISTRIBUSI SENTIMEN REAL DATA:\")\n",
    "for sentiment, percentage in sentiment_dist.items():\n",
    "    print(f\"- {sentiment.upper()}: {percentage:.1f}%\")\n",
    "\n",
    "# Model performance with real variables\n",
    "print(f\"\\nü§ñ PERFORMA MODEL SVM PADA DATA REAL:\")\n",
    "print(f\"- Akurasi: {accuracy:.1%}\")\n",
    "print(f\"- Precision: {precision:.1%}\")\n",
    "print(f\"- Recall: {recall:.1%}\")\n",
    "print(f\"- F1-Score: {f1:.1%}\")\n",
    "print(f\"- Cross-validation: {cv_scores.mean():.1%} (¬±{cv_scores.std():.1%})\")\n",
    "\n",
    "# Key insights\n",
    "print(f\"\\nüí° INSIGHT UTAMA DARI DATA REAL:\")\n",
    "dominant_sentiment = sentiment_dist.idxmax()\n",
    "print(f\"- Sentimen dominan: {dominant_sentiment.upper()} ({sentiment_dist[dominant_sentiment]:.1f}%)\")\n",
    "\n",
    "avg_likes_by_sentiment = processed_df.groupby('sentiment_auto')['like_count'].mean()\n",
    "most_liked_sentiment = avg_likes_by_sentiment.idxmax()\n",
    "print(f\"- Sentimen dengan like terbanyak: {most_liked_sentiment.upper()} (rata-rata {avg_likes_by_sentiment[most_liked_sentiment]:.1f} likes)\")\n",
    "\n",
    "# Channel insights\n",
    "top_channel = processed_df['channel_title'].value_counts().index[0]\n",
    "top_channel_comments = processed_df['channel_title'].value_counts().iloc[0]\n",
    "print(f\"- Channel dengan komentar terbanyak: {top_channel} ({top_channel_comments} komentar)\")\n",
    "\n",
    "# Text analysis insights\n",
    "avg_text_length = processed_df.groupby('sentiment_auto')['text_length'].mean()\n",
    "longest_sentiment = avg_text_length.idxmax()\n",
    "print(f\"- Sentimen dengan teks terpanjang: {longest_sentiment.upper()} (rata-rata {avg_text_length[longest_sentiment]:.0f} karakter)\")\n",
    "\n",
    "print(f\"\\nüìà ANALISIS TEMPORAL:\")\n",
    "daily_comments = processed_df.groupby('date').size()\n",
    "peak_date = daily_comments.idxmax()\n",
    "peak_count = daily_comments.max()\n",
    "print(f\"- Tanggal dengan aktivitas tertinggi: {peak_date} ({peak_count} komentar)\")\n",
    "\n",
    "print(f\"\\nüéØ REKOMENDASI BERDASARKAN ANALISIS REAL DATA:\")\n",
    "print(f\"1. PSSI perlu meningkatkan komunikasi publik untuk mengatasi sentimen negatif ({sentiment_dist['negatif']:.1f}%)\")\n",
    "print(f\"2. Manfaatkan sentimen positif ({sentiment_dist['positif']:.1f}%) untuk membangun dukungan publik\")\n",
    "print(f\"3. Fokus pada engagement di channel-channel populer seperti {top_channel}\")\n",
    "print(f\"4. Perhatikan pola temporal komentar untuk timing komunikasi yang tepat\")\n",
    "print(f\"5. Model SVM dengan akurasi {accuracy:.1%} dapat digunakan untuk monitoring sentimen real-time\")\n",
    "\n",
    "print(f\"\\nüî¨ METODOLOGI DAN VALIDASI:\")\n",
    "print(f\"- Dataset: {len(processed_df):,} komentar YouTube real dari {processed_df['video_id'].nunique()} video\")\n",
    "print(f\"- Preprocessing: Text cleaning, normalisasi bahasa Indonesia, TF-IDF vectorization\")\n",
    "print(f\"- Model: SVM dengan kernel RBF (C=1.0, gamma=scale)\")\n",
    "print(f\"- Validasi: 5-fold cross-validation dengan akurasi rata-rata {cv_scores.mean():.1%}\")\n",
    "print(f\"- Feature engineering: TF-IDF dengan 5000 fitur, n-gram (1,2)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ ANALISIS SENTIMEN DATA REAL SELESAI!\")\n",
    "print(\"üìä Model telah divalidasi dengan data real dan siap untuk deployment.\")\n",
    "print(\"üéØ Insight yang diperoleh dapat digunakan untuk strategi komunikasi PSSI.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}